{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a21f5a0",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae616958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import time \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, MaxPool2D, BatchNormalization,Input,Flatten, LeakyReLU, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from Models import yoloModel\n",
    "from Models import alpha_model\n",
    "from scipy.optimize import fsolve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31952e0",
   "metadata": {},
   "source": [
    "# The used paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee1d15d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The file locations\n",
    "file_path=\"./kitti/data_object_label_2/training/label_2/\"\n",
    "image_path=\"./kitti/data_object_image_2/training/image_2/\"\n",
    "test_path=\"./kitti/data_object_image_3/testing/image_3/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f077bd82",
   "metadata": {},
   "source": [
    "# Camera and classes parameters of the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa548e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The average dimentions of the objects in the kitti dataset\n",
    "dims_avg = {'Cyclist': np.array([ 1.73532436,  0.58028152,  1.77413709]), \n",
    "            'Van': np.array([ 2.18928571,  1.90979592,  5.07087755]), \n",
    "            'Tram': np.array([  3.56092896,   2.39601093,  18.34125683]), \n",
    "            'Car': np.array([ 1.52159147,  1.64443089,  3.85813679]), \n",
    "            'Pedestrian': np.array([ 1.75554637,  0.66860882,  0.87623049]),\n",
    "            'Truck': np.array([  3.07392252,   2.63079903,  11.2190799 ])}  \n",
    "\n",
    "fx=725   #focal length on the x-axis\n",
    "fy=370   #focal length on the y-axis\n",
    "fov=1.6372261694540755 # The field of view angle about the y-axis\n",
    "x_c=610 #Center position of the image on the x-axis\n",
    "y_c=175 #Center position of the image on the y-axis\n",
    "BIN=16 #The number of bins for the orientation model\n",
    "Iw=1242 #image width\n",
    "Ih=375 #image height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73060cb",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6df709fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads the kitti dataset images\n",
    "def read_text_image_file(n,test=False):\n",
    "    file='00'\n",
    "    file=file+str(int(n/1000)%10)\n",
    "    file=file+str(int(n/100)%10)\n",
    "    file=file+str(int(n/10)%10)\n",
    "    file=file+str(int(n/1)%10)\n",
    "    if(test):\n",
    "        file_image=test_path+file+\".png\"\n",
    "    else:\n",
    "        file_image=image_path+file+\".png\"\n",
    "    file=file+\".txt\"\n",
    "    file1=open(file_path+file,'r')\n",
    "    lines=file1.readlines()\n",
    "    image=cv2.imread(file_image,cv2.IMREAD_COLOR)\n",
    "    return lines,image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9369133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the information from the kitti dataset, for training \n",
    "def get_data_line(data):\n",
    "    j=0\n",
    "    x=data.split()\n",
    "    data_dict={\"label\":x[0],\n",
    "               \"truncated\":x[1],\n",
    "               \"occluded\":x[2],\n",
    "               \"alpha\":float(x[3]),\n",
    "               \"box\":[float(x[4]),float(x[5]),float(x[6]),float(x[7])],\n",
    "               \"Dims\":[float(x[8]),float(x[9]),float(x[10])],\n",
    "               \"location\":[float(x[11]),float(x[12]),float(x[13])],\n",
    "                \"rotation_y\":float(x[14])}\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32162abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to get the angle of the object about the y axis using the apparent angle in the image\n",
    "def get_rot_y(data_dict_loc,field_of_view=fov):\n",
    "    xc=(data_dict_loc[\"box\"][2]+data_dict_loc[\"box\"][0])/2\n",
    "    Xc=xc-x_c\n",
    "    theta_ray=(3*np.pi/2)+(Xc/1242)*field_of_view\n",
    "    if(data_dict_loc[\"alpha\"]<0):\n",
    "        alpha=2*np.pi+data_dict_loc[\"alpha\"]\n",
    "    else:\n",
    "        alpha=data_dict_loc[\"alpha\"]\n",
    "    theta_y=alpha+theta_ray-3*np.pi/2\n",
    "    \n",
    "    if(theta_y>2*np.pi):\n",
    "        theta_y=theta_y-2*np.pi\n",
    "    \n",
    "    if(theta_y>np.pi):\n",
    "        theta_y=theta_y-2*np.pi\n",
    "    if(theta_y<-np.pi):\n",
    "        theta_y=theta_y+2*np.pi\n",
    "    \n",
    "    return theta_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbbb92e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the rotation matrix \n",
    "def get_rotation_y_mat(data):\n",
    "    t_y=data_dict[\"rotation_y\"]\n",
    "    Mat_y=np.array([[np.cos(t_y),0,np.sin(t_y)],\n",
    "           [0,1,0],\n",
    "           [-np.sin(t_y),0,np.cos(t_y)]])\n",
    "    return Mat_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57dd3278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the relation between the camera frame and the image frame\n",
    "def get_projection_mat(point,fx=fx,fy=fy): \n",
    "    #Get the projection matrix as [[fx/z,0,0],[0,fy/z,0]]\n",
    "    Z=point[2]\n",
    "    P=[[fx/Z,0,0],\n",
    "       [0,fy/Z,0]]\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "165454be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the position of the object using the geometric constraints\n",
    "def get_translation(data,x0):\n",
    "\n",
    "    \n",
    "    alpha=data[\"alpha\"]\n",
    " \n",
    "    L=data[\"Dims\"][2]  # The length of the object\n",
    "    W=data[\"Dims\"][1]  # The width of the object\n",
    "\n",
    "    \n",
    "    xi_r=data[\"box\"][2]-x_c  #The position of the right most pixel if the 2D bounding box\n",
    "    xi_l=data[\"box\"][0]-x_c  #The position of the left most pixel if the 2D bounding box\n",
    "\n",
    "\n",
    "    yi=0.5*(data[\"box\"][1]+data[\"box\"][3])-y_c\n",
    "    \n",
    "    # (Xcr,Ycr) is the coordinates of the right most edge of the car\n",
    "    # (Xcl,Ycl) is the coordinates of the left most edge of the car\n",
    "    \n",
    "    if(alpha<=-np.pi/2):\n",
    "        Xcr=-(L/2)\n",
    "        Zcr=-(W/2)\n",
    "        Xcl=(L/2)\n",
    "        Zcl=(W/2)\n",
    "\n",
    "    elif(alpha<=0):\n",
    "        Xcr=(L/2)\n",
    "        Zcr=-(W/2)\n",
    "        Xcl=-(L/2)\n",
    "        Zcl=(W/2)\n",
    "\n",
    "    elif(alpha<=np.pi/2):\n",
    "        Xcr=(L/2)\n",
    "        Zcr=(W/2)\n",
    "        Xcl=-(L/2)\n",
    "        Zcl=-(W/2)\n",
    "\n",
    "    else:\n",
    "        Xcr=-(L/2)\n",
    "        Zcr=(W/2)\n",
    "        Xcl=(L/2)\n",
    "        Zcl=-(W/2)\n",
    "\n",
    "    # Geometric constraints between the 2D bounding box and the actual object\n",
    "    def constraints(Input):\n",
    "        Tx,Ty,Tz=Input\n",
    "        \n",
    "        \n",
    "        eq1=(Tz)*(xi_r/fx)-Xcr*np.cos(alpha)-Zcr*np.sin(alpha)-Tx\n",
    "        eq3=(Tz)*(xi_l/fx)-Xcl*np.cos(alpha)-Zcl*np.sin(alpha)-Tx\n",
    "        eq5=(Ty/Tz)-(yi/fy)\n",
    "        \n",
    "        return [eq1,eq3,eq5]\n",
    "    out=fsolve(constraints,x0)\n",
    "    if(out[2]<0):\n",
    "        out=-out\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd872388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw the 3D box \n",
    "def Draw_box(data_dict,image):\n",
    "    perm=[seq for seq in itertools.product([-1,1], repeat=3)]\n",
    "    Points=[]\n",
    "    rotation=get_rotation_y_mat(data_dict)\n",
    "    for seq in perm:\n",
    "        point_car=np.array(list(map(lambda x: 0.5*x,data_dict[\"Dims\"]))) # The point in the car frame\n",
    "        point_car=np.array([point_car[2],point_car[0],point_car[1]])\n",
    "        point_car=point_car*seq\n",
    "        point_cam=data_dict[\"location\"]+np.dot(rotation,point_car) # The point in the camera frame\n",
    "        project_mat=get_projection_mat(point_cam)\n",
    "        project_point=np.dot(project_mat,point_cam)+ np.array([610,175])# The point in the image\n",
    "        Points=Points+[project_point]\n",
    "        \n",
    "    for i in range(len(Points)):\n",
    "        cv2.circle(image,(int(Points[i][0]),int(Points[i][1])),2,(255,0,0),2)\n",
    "        for j in range (len(Points)-1):\n",
    "            if sum(abs(np.array(perm[i])-np.array(perm[j])))>=4:\n",
    "                continue\n",
    "            else:\n",
    "                cv2.line(image, (int(Points[i][0]),int(Points[i][1])), (int(Points[j][0]),int(Points[j][1])),(255,0,0),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2dd317",
   "metadata": {},
   "source": [
    "# Load the deep learning models used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93617ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mar/Documents/Masters/Masters_env/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5670467400>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load yolo model\n",
    "yolo=yoloModel.YoloV3(size=416,classes=80)\n",
    "weights_path='./Checkpoints/yolov3.tf'\n",
    "yolo.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9ed6ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_model=alpha_model.Get_Model(BIN=BIN)\n",
    "angle_model.load_weights(\"./Checkpoints/angle_16_Bin_5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0f4b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the range for each bin\n",
    "step=2*np.pi/BIN\n",
    "bin_ranges=[[-np.pi+i*step,-np.pi+(i+1)*step] for i in range(BIN)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a85c4c7",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cff7f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.98971224 0.8785205  0.82696307 0.6382371  0.5124569  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]], shape=(1, 100), dtype=float32)\n",
      "The elapsed time is 0.9911675453186035\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kitti_image_number=3107\n",
    "thres=0.6\n",
    "_,image=read_text_image_file(kitti_image_number,test=True) #Get the image\n",
    "\n",
    "\n",
    "#image=image.astype(\"uint8\")\n",
    "\n",
    "img=np.expand_dims(image,0)\n",
    "img=tf.image.resize(img,(416,416))\n",
    "\n",
    "img=img/255\n",
    "\n",
    "data_dict={}\n",
    "\n",
    "t=time.time()\n",
    "boxes, scores, classes, nums = yolo(img)\n",
    "print(scores)\n",
    "boxes_2=boxes[scores>thres]\n",
    "classes_2=classes[scores>thres]\n",
    "for box,Class in zip(boxes_2,classes_2):\n",
    "    f=0\n",
    "    if(Class==2):\n",
    "        data_dict[\"Dims\"]=dims_avg[\"Car\"]\n",
    "        f=1\n",
    "    elif Class==0:\n",
    "        data_dict[\"Dims\"]=dims_avg[\"Pedestrian\"]\n",
    "        f=1\n",
    "    if(f==1):\n",
    "        box_2=box*np.array([Iw,Ih,Iw,Ih])\n",
    "        data_dict[\"box\"]=box_2\n",
    "        img_cropped=image[np.max([int(box_2[1]),0]):int(box_2[3]),np.max([int(box_2[0]),0]):int(box_2[2]),:]\n",
    "        img_cropped=cv2.resize(img_cropped,(64,64))\n",
    "        bins_prob=angle_model(np.expand_dims(img_cropped,0))\n",
    "        n_bin=np.argmax(bins_prob)\n",
    "        alpha=np.mean(bin_ranges[n_bin])\n",
    "        data_dict[\"alpha\"]=alpha\n",
    "        T=get_translation(data_dict,[1,1,1])\n",
    "        data_dict[\"location\"]=list(T)\n",
    "        data_dict[\"rotation_y\"]=get_rot_y(data_dict,fov)\n",
    "        Draw_box(data_dict,image)\n",
    "    \n",
    "dt=time.time()-t\n",
    "print(\"The elapsed time is \"+str(dt))\n",
    "cv2.imshow(\"Annotated image\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
